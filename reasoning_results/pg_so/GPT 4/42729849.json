{"res": "Based on the scenario described and the issues you are facing with deadlocks in PostgreSQL, here are some recommended parameters and practices to consider:\n\n1. **`deadlock_timeout`**: This parameter specifies the amount of time to wait on a lock before checking to see if there is a deadlock. Reducing this value can help in faster detection of deadlocks, though it won't prevent them. The default is usually 1 second. You might want to adjust this slightly lower to detect deadlocks quicker, but be cautious as too low a value might cause unnecessary overhead.\n\n2. **`max_locks_per_transaction`**: This parameter controls the maximum number of locks a single transaction can hold. Since your application seems to lock the table and then perform updates, increasing this value might help if the number of locks is a limiting factor. However, this is generally more of a concern with a large number of rows being locked.\n\n3. **Use of `SKIP LOCKED`**: As you've discovered, `SKIP LOCKED` is a powerful feature introduced in PostgreSQL 9.5 that allows you to ignore rows that are locked by other transactions. This can be particularly useful in implementing queue-like functionality where you want multiple workers to pick up different tasks without interfering with each other. Consider using `SELECT ... FOR UPDATE SKIP LOCKED` to select the next available task.\n\n4. **`statement_timeout`**: This parameter can be set to automatically abort any database query that takes longer than the specified amount of time. This can prevent long-running queries from holding locks for too long, potentially contributing to deadlocks.\n\n5. **Optimize transaction lengths**: Ensure that transactions are as short as possible to reduce the window during which locks are held. This means performing only necessary operations within the transaction and committing as soon as possible.\n\n6. **Review isolation levels**: Although you are using `READ COMMITTED`, which is generally suitable for many applications, ensure this setting is appropriate for your specific concurrency and consistency requirements. Sometimes adjusting the isolation level can change the locking behavior.\n\n7. **Application logic review**: Beyond database parameters, review the application logic to ensure that transactions are structured optimally. For example, always acquire locks in a consistent order and avoid unnecessary locks.\n\n8. **Connection pooling**: If not already implemented, consider using connection pooling (e.g., via PgBouncer) to manage database connections efficiently. This can help reduce the overhead of establishing connections and might indirectly impact how transactions are managed.\n\n9. **Monitoring and logging**: Enhance monitoring and logging to capture more detailed information about when and where deadlocks occur. This can help in fine-tuning both application logic and database settings.\n\n10. **Concurrency testing**: Perform more extensive concurrency testing to simulate higher loads and more complex interactions, which might help in reproducing and understanding the deadlock scenarios better.\n\nThese recommendations aim to address both the immediate deadlock issues and provide a more robust framework for handling concurrency in your PostgreSQL database."}